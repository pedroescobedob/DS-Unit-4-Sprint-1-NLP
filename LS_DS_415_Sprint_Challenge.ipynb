{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "# Sprint Challenge\n",
    "## *Data Science Unit 4 Sprint 1*\n",
    "\n",
    "After a week of Natural Language Processing, you've learned some cool new stuff: how to process text, how turn text into vectors, and how to model topics from documents. Apply your newly acquired skills to one of the most famous NLP datasets out there: [Yelp](https://www.yelp.com/dataset/challenge). As part of the job selection process, some of my friends have been asked to create analysis of this dataset, so I want to empower you to have a head start.  \n",
    "\n",
    "The real dataset is massive (almost 8 gigs uncompressed). I've sampled the data for you to something more managable for the Sprint Challenge. You can analyze the full dataset as a stretch goal or after the sprint challenge. As you work on the challenge, I suggest adding notes about your findings and things you want to analyze in the future.\n",
    "\n",
    "## Challenge Objectives\n",
    "*Successfully complete these all these objectives to earn a 2. There are more details on each objective further down in the notebook.*\n",
    "* <a href=\"#p1\">Part 1</a>: Write a function to tokenize the yelp reviews\n",
    "* <a href=\"#p2\">Part 2</a>: Create a vector representation of those tokens\n",
    "* <a href=\"#p3\">Part 3</a>: Use your tokens in a classification model on yelp rating\n",
    "* <a href=\"#p4\">Part 4</a>: Estimate & Interpret a topic model of the Yelp reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "yelp = pd.read_json('./data/review_sample.json', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>cool</th>\n",
       "      <th>date</th>\n",
       "      <th>funny</th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>useful</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nDuEqIyRc8YKS1q1fX0CZg</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-03-31 16:50:30</td>\n",
       "      <td>0</td>\n",
       "      <td>eZs2tpEJtXPwawvHnHZIgQ</td>\n",
       "      <td>1</td>\n",
       "      <td>BEWARE!!! FAKE, FAKE, FAKE....We also own a sm...</td>\n",
       "      <td>10</td>\n",
       "      <td>n1LM36qNg4rqGXIcvVXv8w</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>eMYeEapscbKNqUDCx705hg</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-12-16 05:31:03</td>\n",
       "      <td>0</td>\n",
       "      <td>DoQDWJsNbU0KL1O29l_Xug</td>\n",
       "      <td>4</td>\n",
       "      <td>Came here for lunch Togo. Service was quick. S...</td>\n",
       "      <td>0</td>\n",
       "      <td>5CgjjDAic2-FAvCtiHpytA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6Q7-wkCPc1KF75jZLOTcMw</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-06-20 19:14:48</td>\n",
       "      <td>1</td>\n",
       "      <td>DDOdGU7zh56yQHmUnL1idQ</td>\n",
       "      <td>3</td>\n",
       "      <td>I've been to Vegas dozens of times and had nev...</td>\n",
       "      <td>2</td>\n",
       "      <td>BdV-cf3LScmb8kZ7iiBcMA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>k3zrItO4l9hwfLRwHBDc9w</td>\n",
       "      <td>3</td>\n",
       "      <td>2010-07-13 00:33:45</td>\n",
       "      <td>4</td>\n",
       "      <td>LfTMUWnfGFMOfOIyJcwLVA</td>\n",
       "      <td>1</td>\n",
       "      <td>We went here on a night where they closed off ...</td>\n",
       "      <td>5</td>\n",
       "      <td>cZZnBqh4gAEy4CdNvJailQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6hpfRwGlOzbNv7k5eP9rsQ</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-06-30 02:30:01</td>\n",
       "      <td>0</td>\n",
       "      <td>zJSUdI7bJ8PNJAg4lnl_Gg</td>\n",
       "      <td>4</td>\n",
       "      <td>3.5 to 4 stars\\n\\nNot bad for the price, $12.9...</td>\n",
       "      <td>5</td>\n",
       "      <td>n9QO4ClYAS7h9fpQwa5bhA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id  cool                date  funny  \\\n",
       "0  nDuEqIyRc8YKS1q1fX0CZg     1 2015-03-31 16:50:30      0   \n",
       "1  eMYeEapscbKNqUDCx705hg     0 2015-12-16 05:31:03      0   \n",
       "2  6Q7-wkCPc1KF75jZLOTcMw     1 2010-06-20 19:14:48      1   \n",
       "3  k3zrItO4l9hwfLRwHBDc9w     3 2010-07-13 00:33:45      4   \n",
       "4  6hpfRwGlOzbNv7k5eP9rsQ     1 2018-06-30 02:30:01      0   \n",
       "\n",
       "                review_id  stars  \\\n",
       "0  eZs2tpEJtXPwawvHnHZIgQ      1   \n",
       "1  DoQDWJsNbU0KL1O29l_Xug      4   \n",
       "2  DDOdGU7zh56yQHmUnL1idQ      3   \n",
       "3  LfTMUWnfGFMOfOIyJcwLVA      1   \n",
       "4  zJSUdI7bJ8PNJAg4lnl_Gg      4   \n",
       "\n",
       "                                                text  useful  \\\n",
       "0  BEWARE!!! FAKE, FAKE, FAKE....We also own a sm...      10   \n",
       "1  Came here for lunch Togo. Service was quick. S...       0   \n",
       "2  I've been to Vegas dozens of times and had nev...       2   \n",
       "3  We went here on a night where they closed off ...       5   \n",
       "4  3.5 to 4 stars\\n\\nNot bad for the price, $12.9...       5   \n",
       "\n",
       "                  user_id  \n",
       "0  n1LM36qNg4rqGXIcvVXv8w  \n",
       "1  5CgjjDAic2-FAvCtiHpytA  \n",
       "2  BdV-cf3LScmb8kZ7iiBcMA  \n",
       "3  cZZnBqh4gAEy4CdNvJailQ  \n",
       "4  n9QO4ClYAS7h9fpQwa5bhA  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Tokenize Function\n",
    "<a id=\"#p1\"></a>\n",
    "\n",
    "Complete the function `tokenize`. Your function should\n",
    "- accept one document at a time\n",
    "- return a list of tokens\n",
    "\n",
    "You are free to use any method you have learned this week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(doc):\n",
    "    tokens = re.sub(r'[^a-zA-z ^0-9]', '', doc)\n",
    "    tokens = tokens.lower().split()\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Vector Representation\n",
    "<a id=\"#p2\"></a>\n",
    "1. Create a vector representation of the reviews\n",
    "2. Write a fake review and query for the 10 most similiar reviews, print the text of the reviews. Do you notice any patterns?\n",
    "    - Given the size of the dataset, it will probably be best to use a `NearestNeighbors` model for this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import spacy\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_soup(df_column, spec_chars_remove = []):\n",
    "    \"\"\"\n",
    "    Input: dataframe column and list of specific characters to remove, \n",
    "    \n",
    "    Output: List of cleaned observations\n",
    "    \"\"\"\n",
    "    \n",
    "    df_column = df_column.copy()\n",
    "    \n",
    "    soupy = [BeautifulSoup(df_column[ii], 'lxml').get_text() \n",
    "             for ii in range(df_column.shape[0])\n",
    "            ]\n",
    "    \n",
    "    for char in spec_chars_remove:\n",
    "        soupy = [soupy[ii].replace(char, ' ') \n",
    "                 for ii in range(len(soupy))\n",
    "                ]\n",
    "        \n",
    "    to_clean = ['[^A-Za-z ]+', '   ', '  ']\n",
    "    \n",
    "    for char in to_clean:\n",
    "        soupy = [re.sub(char, ' ', soupy[ii]) \n",
    "                 for ii in range(len(soupy))\n",
    "                ]\n",
    "        \n",
    "    df_feature = pd.Series([nlp(soupy[ii].lower().strip()) \n",
    "                            for ii in range(len(soupy))\n",
    "                           ])\n",
    "        \n",
    "    for row in range(df_feature.shape[0]):\n",
    "        \n",
    "        tokens = [token.lemma_ for token in df_feature[row]]\n",
    "        \n",
    "        tokens_redo = []\n",
    "    \n",
    "        for ii in range(len(tokens)):\n",
    "        \n",
    "            if (len(tokens[ii]) > 2) & ~(tokens[ii] == '-PRON-'):\n",
    "                tokens_redo.append(tokens[ii])\n",
    "        \n",
    "        df_feature[row] = \" \".join(tokens_redo)\n",
    "         \n",
    "    return df_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "yelp['text_cleaned'] = clean_soup(yelp['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = nlp.Defaults.stop_words.union(['review', 'pron', 'star', \n",
    "                                            'place','food', 'time', 'good',\n",
    "                                            'come', 'order', 'experience'\n",
    "                                            'service', 'know', 'restaurant',\n",
    "                                            'want', 'wait', 'till', 'think',\n",
    "                                            'tell', 'look', 'minute', 'year',\n",
    "                                            'find', 'thing', 'people', 'great',\n",
    "                                            'need', 'price', 'work', 'service',\n",
    "                                            'like', 'try' ,'love'\n",
    "                                            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/open/opt/anaconda3/envs/U4-S1-NLP/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ll', 've'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>absolute</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>aburi</th>\n",
       "      <th>acai</th>\n",
       "      <th>accent</th>\n",
       "      <th>accept</th>\n",
       "      <th>acceptable</th>\n",
       "      <th>access</th>\n",
       "      <th>...</th>\n",
       "      <th>zach</th>\n",
       "      <th>zen</th>\n",
       "      <th>zero</th>\n",
       "      <th>zest</th>\n",
       "      <th>zip</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoo</th>\n",
       "      <th>zucchini</th>\n",
       "      <th>zumba</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 5000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ability  able  absolute  absolutely  aburi  acai  accent  accept  \\\n",
       "0      0.0   0.0       0.0         0.0    0.0   0.0     0.0     0.0   \n",
       "1      0.0   0.0       0.0         0.0    0.0   0.0     0.0     0.0   \n",
       "2      0.0   0.0       0.0         0.0    0.0   0.0     0.0     0.0   \n",
       "3      0.0   0.0       0.0         0.0    0.0   0.0     0.0     0.0   \n",
       "4      0.0   0.0       0.0         0.0    0.0   0.0     0.0     0.0   \n",
       "\n",
       "   acceptable  access  ...  zach  zen  zero  zest  zip  zombie  zone  zoo  \\\n",
       "0         0.0     0.0  ...   0.0  0.0   0.0   0.0  0.0     0.0   0.0  0.0   \n",
       "1         0.0     0.0  ...   0.0  0.0   0.0   0.0  0.0     0.0   0.0  0.0   \n",
       "2         0.0     0.0  ...   0.0  0.0   0.0   0.0  0.0     0.0   0.0  0.0   \n",
       "3         0.0     0.0  ...   0.0  0.0   0.0   0.0  0.0     0.0   0.0  0.0   \n",
       "4         0.0     0.0  ...   0.0  0.0   0.0   0.0  0.0     0.0   0.0  0.0   \n",
       "\n",
       "   zucchini  zumba  \n",
       "0       0.0    0.0  \n",
       "1       0.0    0.0  \n",
       "2       0.0    0.0  \n",
       "3       0.0    0.0  \n",
       "4       0.0    0.0  \n",
       "\n",
       "[5 rows x 5000 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vectorize cleaned text\n",
    "tfidf = TfidfVectorizer(stop_words = stop_words, max_features = 5000)\n",
    "\n",
    "dtm = tfidf.fit_transform(yelp['text_cleaned'])\n",
    "\n",
    "dtm = pd.DataFrame(dtm.todense(), columns = tfidf.get_feature_names())\n",
    "\n",
    "dtm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NearestNeighbors(algorithm='kd_tree', leaf_size=30, metric='minkowski',\n",
       "                 metric_params=None, n_jobs=None, n_neighbors=10, p=2,\n",
       "                 radius=1.0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn = NearestNeighbors(n_neighbors = 10, algorithm ='kd_tree')\n",
    "nn.fit(dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_review = [\"\"\"This was the greatest place to have lunch, \n",
    "                    the atmosphere was great, food was great, \n",
    "                    service was outstanding. Cheap prices, \n",
    "                    great lunch deals\"\"\"]\n",
    "\n",
    "fake = tfidf.transform(fake_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stars:\n",
      " 6625    3\n",
      "469     4\n",
      "5129    5\n",
      "6204    5\n",
      "3693    4\n",
      "6311    5\n",
      "555     3\n",
      "6787    1\n",
      "4195    5\n",
      "6920    3\n",
      "Name: stars, dtype: int64\n",
      "\n",
      "                Review:\n",
      " 6625    Food and service are ok. There are much better...\n",
      "469     O  o  thenk 6nnn  .b  cgv  xx TV cvg  9 nvehxc...\n",
      "5129                               Best place everrrrr!!!\n",
      "6204    旅行でラスベガスに来ましたがネイルがはげてるのが気になり、探したお店でした。\\n質問にも丁寧...\n",
      "3693          I love YC's! Its really good for the price.\n",
      "6311    天氣很熱吃不下東西，今天我點了一個韓國冷面湯、餐後點了甜點，冰沙系列不會太甜膩，覺得店家很用...\n",
      "555     Chingu Korean BBQ's Lunch Specials for $5.99! ...\n",
      "6787    I got a lunch special, it was cheap and it was...\n",
      "4195    Loved our lunch here!   Lobster Cobb was incre...\n",
      "6920    I've never been too fond of Laredo's. A cowork...\n",
      "Name: text, dtype: object\n",
      "\n",
      "                Review Cleaned:\n",
      " 6625     food and service there much well place for lunch\n",
      "469     thenk nnn cgv cvg nvehxcfvvv and the vghvhridd...\n",
      "5129                                  good place everrrrr\n",
      "6204                                                     \n",
      "3693                       love really good for the price\n",
      "6311                                                     \n",
      "555     chingu korean bbq lunch special for choice for...\n",
      "6787    get lunch special cheap and terrible will neve...\n",
      "4195    love lunch here lobster cobb incredible beer f...\n",
      "6920    never too fond laredo coworker talk into for l...\n",
      "Name: text_cleaned, dtype: object\n"
     ]
    }
   ],
   "source": [
    "nearest_vectors, nearest_loc = nn.kneighbors(fake.todense())\n",
    "\n",
    "for neighbor in list(nearest_loc):\n",
    "    print(f\"\"\"Stars:\\n {yelp['stars'].iloc[neighbor]}\\n\n",
    "                Review:\\n {yelp['text'].iloc[neighbor][0:300]}\\n\n",
    "                Review Cleaned:\\n {yelp['text_cleaned'].iloc[neighbor][0:300]}\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Classification\n",
    "<a id=\"#p3\"></a>\n",
    "Your goal in this section will be to predict `stars` from the review dataset. \n",
    "\n",
    "1. Create a piepline object with a sklearn `CountVectorizer` or `TfidfVector` and any sklearn classifier. Use that pipeline to estimate a model to predict `stars`. Use the Pipeline to predict a star rating for your fake review from Part 2. \n",
    "2. Tune the entire pipeline with a GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from scipy.stats import randint, uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9000,), (1000,), (9000,), (1000,))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(yelp['text_cleaned'], yelp['stars'],\n",
    "                                                  test_size=0.10, random_state=42, stratify = yelp['stars'])\n",
    "\n",
    "X_train.shape, X_val.shape, y_train.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer(stop_words=stop_words)\n",
    "\n",
    "rfc = RandomForestClassifier()\n",
    "\n",
    "svd = TruncatedSVD(algorithm='randomized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:   36.2s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done  38 out of  48 | elapsed:  3.4min remaining:   53.4s\n",
      "[Parallel(n_jobs=-1)]: Done  43 out of  48 | elapsed:  3.7min remaining:   26.1s\n",
      "[Parallel(n_jobs=-1)]: Done  48 out of  48 | elapsed:  4.0min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  48 out of  48 | elapsed:  4.0min finished\n",
      "/Users/open/opt/anaconda3/envs/U4-S1-NLP/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ll', 've'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.5582222222222222\n",
      "\n",
      "Best hyperparameters: \n",
      "{'clf__class_weight': None, 'clf__max_depth': 40, 'clf__max_features': 0.88, 'clf__min_samples_leaf': 5, 'clf__n_estimators': 250, 'lsi__svd__n_components': 30, 'lsi__vect__max_df': 0.95, 'lsi__vect__max_features': 5000, 'lsi__vect__min_df': 0.01, 'lsi__vect__ngram_range': (1, 1)}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# pipline using latent semantic indexing\n",
    "\n",
    "lsi = Pipeline([('vect', vect), \n",
    "                ('svd', svd)])\n",
    "\n",
    "pipeline = Pipeline([('lsi', lsi),\n",
    "                 ('clf', rfc)])\n",
    "\n",
    "# The pipeline puts together a bunch fit then transform,fit then predict.\n",
    "parameters = {\n",
    "    'lsi__vect__ngram_range': [(1, 1), (1, 2)],\n",
    "    'lsi__vect__max_df': [.95],\n",
    "    'lsi__vect__min_df': [.01],\n",
    "    'lsi__vect__max_features': [5000],\n",
    "    'lsi__svd__n_components': [30],\n",
    "    'clf__min_samples_leaf': [5, 24],\n",
    "    'clf__n_estimators': [250],\n",
    "    'clf__max_depth': [20, 40],\n",
    "    'clf__max_features': [0.88, 0.98],\n",
    "    'clf__class_weight': [None] \n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    pipeline, \n",
    "    parameters,  \n",
    "    cv = 3, \n",
    "    verbose = 10,\n",
    "    n_jobs = -1\n",
    ")\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f'Best score: {grid_search.best_score_}\\n')\n",
    "print(f'Best hyperparameters: \\n{grid_search.best_params_}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy:\n",
      "0.564\n"
     ]
    }
   ],
   "source": [
    "best_pipeline = grid_search.best_estimator_\n",
    "best_pipeline.fit(X_train, y_train)\n",
    "\n",
    "print(f'Validation Accuracy:\\n{best_pipeline.score(X_val, y_val)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.54      0.65      0.59       150\n",
      "           2       0.18      0.03      0.05        76\n",
      "           3       0.32      0.15      0.20       110\n",
      "           4       0.43      0.34      0.38       218\n",
      "           5       0.64      0.84      0.73       446\n",
      "\n",
      "    accuracy                           0.56      1000\n",
      "   macro avg       0.42      0.40      0.39      1000\n",
      "weighted avg       0.51      0.56      0.52      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grid_pred = best_pipeline.predict(X_val)\n",
    "print(classification_report(y_val, grid_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The model predicts my fake review would give\n",
      "the location a rating of 5 stars.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fake_review_pred = best_pipeline.predict(fake_review)\n",
    "\n",
    "print(f\"\"\"\n",
    "The model predicts my fake review would give\n",
    "the location a rating of {fake_review_pred[0]} stars.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Topic Modeling\n",
    "\n",
    "Let's find out what those yelp reviews are saying! :D\n",
    "\n",
    "1. Estimate a LDA topic model of the review text\n",
    "    - Keep the `iterations` parameter at or below 5 to reduce run time\n",
    "    - The `workers` parameter should match the number of physical cores on your machine.\n",
    "2. Create 1-2 visualizations of the results\n",
    "    - You can use the most important 3 words of a topic in relevant visualizations. Refer to yesterday's notebook to extract. \n",
    "3. In markdown, write 1-2 paragraphs of analysis on the results of your topic model\n",
    "\n",
    "__*Note*__: You can pass the DataFrame column of text reviews to gensim. You do not have to use a generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "from gensim.models import LdaMulticore\n",
    "from gensim.corpora import Dictionary\n",
    "from spacy.tokenizer import Tokenizer\n",
    "import pyLDAvis.gensim\n",
    "import warnings #for LDA warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learn the vocubalary of the yelp data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_tokens(df_feature, addl_stop_words = ['-PRON-']):\n",
    "    \"\"\"\n",
    "    Input: Column of a dataframe/ Pandas Series, \n",
    "    stop words you'd like to add to nlp's defaults\n",
    "    \n",
    "    Output: List consisting of tokens for each observation\n",
    "    \n",
    "    Assumes: nlp object initialized as nlp\n",
    "    \"\"\"\n",
    "    \n",
    "    tokens = []\n",
    "    tokenizer = Tokenizer(nlp.vocab)\n",
    "\n",
    "    STOP_WORDS = nlp.Defaults.stop_words.union(addl_stop_words)\n",
    "\n",
    "    for doc in tokenizer.pipe(df_feature, batch_size=500):\n",
    "\n",
    "        doc_tokens = []\n",
    "\n",
    "        for token in doc: \n",
    "            if token.text not in STOP_WORDS:\n",
    "                doc_tokens.append(token.text.lower())\n",
    "\n",
    "        tokens.append(doc_tokens)\n",
    "\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [beware, fake, fake, fake, small, business, lo...\n",
       "1    [lunch, togo, quick, staff, friendly, complain...\n",
       "2    [vegas, dozen, step, foot, circus, circus, rea...\n",
       "3    [night, close, street, party, actually, group,...\n",
       "4    [bad, lunch, senior, pay, eat, hot, salad, noo...\n",
       "Name: text_tokens, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp['text_tokens'] = make_tokens(yelp['text_cleaned'], stop_words)\n",
    "yelp['text_tokens'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2word = Dictionary(yelp['text_tokens'])\n",
    "id2word.filter_extremes(no_below=5, no_above=0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a bag of words representation of the entire corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [id2word.doc2bow(text) for text in yelp['text_tokens']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your LDA model should be ready for estimation: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n",
    "\n",
    "lda = LdaMulticore(corpus=corpus,\n",
    "                   id2word=id2word,\n",
    "                   iterations=20,\n",
    "                   workers=6,\n",
    "                   num_topics = 3 # tuned after initial results of pyLDAvis\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ Topic 0 ------\n",
      "nice drink eat\n",
      "\n",
      "------ Topic 1 ------\n",
      "day nice don\n",
      "\n",
      "------ Topic 2 ------\n",
      "don experience little\n",
      "\n"
     ]
    }
   ],
   "source": [
    "words = [re.findall(r'\"([^\"]*)\"', t[1]) for t in lda.print_topics()]\n",
    "\n",
    "topics = [' '.join(t[0:3]) for t in words]\n",
    "\n",
    "for id, t in enumerate(topics): \n",
    "    print(f\"------ Topic {id} ------\")\n",
    "    print(t, end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create 1-2 visualizations of the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el8056048449380089445094953\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el8056048449380089445094953_data = {\"mdsDat\": {\"x\": [-0.010549753662372992, 0.006954941469071704, 0.0035948121933012853], \"y\": [-0.0017750811594743781, -0.007472257850434984, 0.009247339009909362], \"topics\": [1, 2, 3], \"cluster\": [1, 1, 1], \"Freq\": [37.424339294433594, 32.28632736206055, 30.289331436157227]}, \"tinfo\": {\"Term\": [\"day\", \"sure\", \"experience\", \"pay\", \"amazing\", \"coffee\", \"don\", \"small\", \"visit\", \"charge\", \"nice\", \"bad\", \"check\", \"new\", \"awesome\", \"meat\", \"night\", \"salad\", \"right\", \"excellent\", \"nail\", \"leave\", \"lunch\", \"sit\", \"table\", \"roll\", \"away\", \"shop\", \"walk\", \"use\", \"cosmo\", \"isn\", \"lakewood\", \"wolf\", \"naan\", \"cappuccino\", \"poker\", \"backyard\", \"peruvian\", \"wing\", \"batch\", \"buffalo\", \"knife\", \"coffee\", \"cider\", \"enhance\", \"karaoke\", \"yummm\", \"hollywood\", \"omg\", \"brake\", \"hooter\", \"sip\", \"pos\", \"jean\", \"vegetarian\", \"small\", \"fiend\", \"mrs\", \"lover\", \"cookie\", \"poutine\", \"truly\", \"night\", \"walk\", \"hotel\", \"table\", \"cream\", \"far\", \"burger\", \"cake\", \"finally\", \"dish\", \"drive\", \"area\", \"drink\", \"offer\", \"visit\", \"refill\", \"serve\", \"dinner\", \"chicken\", \"leave\", \"customer\", \"help\", \"nice\", \"eat\", \"friend\", \"beer\", \"use\", \"fry\", \"flavor\", \"meal\", \"staff\", \"location\", \"hour\", \"taste\", \"menu\", \"friendly\", \"didn\", \"day\", \"definitely\", \"ask\", \"delicious\", \"don\", \"recommend\", \"little\", \"lash\", \"christina\", \"mailbox\", \"bike\", \"dutch\", \"nope\", \"vape\", \"tattoo\", \"zero\", \"talented\", \"festival\", \"supportive\", \"tapioca\", \"protein\", \"bella\", \"puppy\", \"promoter\", \"equipment\", \"dumpling\", \"brooklyn\", \"jordan\", \"moscow\", \"roti\", \"fee\", \"bat\", \"singer\", \"spin\", \"print\", \"pierogi\", \"brow\", \"charge\", \"pedicure\", \"nail\", \"shot\", \"root\", \"apartment\", \"day\", \"terrible\", \"woman\", \"rush\", \"check\", \"pay\", \"sell\", \"forward\", \"amazing\", \"line\", \"sure\", \"buy\", \"cook\", \"bbq\", \"color\", \"end\", \"friendly\", \"manager\", \"way\", \"bar\", \"different\", \"car\", \"nice\", \"ask\", \"experience\", \"lot\", \"feel\", \"worth\", \"maybe\", \"new\", \"happy\", \"don\", \"care\", \"didn\", \"definitely\", \"wasn\", \"little\", \"long\", \"customer\", \"chicken\", \"recommend\", \"staff\", \"bad\", \"fresh\", \"hour\", \"taste\", \"eat\", \"pretty\", \"fry\", \"menu\", \"halo\", \"bulwark\", \"urgent\", \"cat\", \"bundle\", \"german\", \"brussels\", \"mochi\", \"compassionate\", \"faucet\", \"prix\", \"peter\", \"mmm\", \"meatloaf\", \"lens\", \"comprehensive\", \"heaping\", \"threaten\", \"neglect\", \"saver\", \"reflexology\", \"bravo\", \"shitty\", \"oct\", \"smith\", \"schedule\", \"realistic\", \"diagnose\", \"dank\", \"whisky\", \"yesterday\", \"terribly\", \"pudding\", \"pho\", \"east\", \"escape\", \"dryer\", \"receptionist\", \"awesome\", \"dessert\", \"month\", \"fruit\", \"excellent\", \"meat\", \"salad\", \"away\", \"lunch\", \"barely\", \"sit\", \"bad\", \"right\", \"vegas\", \"cheese\", \"tea\", \"pizza\", \"don\", \"room\", \"experience\", \"enjoy\", \"menu\", \"delicious\", \"shop\", \"little\", \"highly\", \"new\", \"add\", \"clean\", \"roll\", \"recommend\", \"use\", \"sure\", \"staff\", \"didn\", \"definitely\", \"eat\", \"ask\", \"pretty\", \"drink\", \"lot\", \"amazing\", \"feel\", \"leave\", \"taste\"], \"Freq\": [1557.0, 956.0, 1444.0, 861.0, 1279.0, 654.0, 1892.0, 941.0, 896.0, 492.0, 1786.0, 1210.0, 942.0, 1182.0, 687.0, 685.0, 1029.0, 787.0, 1053.0, 680.0, 360.0, 1035.0, 783.0, 776.0, 1152.0, 567.0, 617.0, 577.0, 897.0, 1110.0, 8.714364051818848, 193.83116149902344, 4.99918794631958, 6.832648754119873, 31.698150634765625, 22.347688674926758, 10.530692100524902, 14.220680236816406, 8.598965644836426, 156.7860870361328, 15.072724342346191, 36.47414779663086, 11.908378601074219, 395.1061706542969, 11.932904243469238, 7.150959491729736, 11.32305908203125, 4.151458263397217, 14.201438903808594, 37.02093505859375, 19.347980499267578, 5.29135274887085, 19.9333553314209, 3.5163216590881348, 15.199786186218262, 74.12325286865234, 553.7445068359375, 3.4750373363494873, 5.7874650955200195, 29.349138259887695, 85.2751235961914, 39.06711196899414, 111.95661163330078, 579.5021362304688, 496.9751281738281, 293.7656555175781, 632.613525390625, 307.4584045410156, 239.23309326171875, 391.1631774902344, 151.72044372558594, 227.63287353515625, 482.7864074707031, 251.34323120117188, 440.35565185546875, 737.499755859375, 347.1412658691406, 461.84307861328125, 79.38117980957031, 361.97906494140625, 366.9985656738281, 678.658447265625, 511.2637634277344, 580.6492919921875, 323.14984130859375, 825.1546020507812, 736.097900390625, 514.4395751953125, 300.9641418457031, 503.0704345703125, 505.9739990234375, 365.5476989746094, 407.3077087402344, 639.7655029296875, 427.5531311035156, 463.4240417480469, 481.0932922363281, 502.74591064453125, 518.96044921875, 549.1973266601562, 546.5596313476562, 518.1008911132812, 535.3885498046875, 477.88470458984375, 577.87451171875, 473.4089660644531, 442.4314880371094, 30.959556579589844, 7.811641216278076, 7.160321235656738, 60.80974578857422, 10.095189094543457, 20.586734771728516, 6.811766147613525, 22.597362518310547, 43.62564468383789, 15.681711196899414, 5.242952346801758, 4.051033020019531, 5.777472496032715, 25.863292694091797, 5.709601402282715, 22.773418426513672, 3.968825101852417, 23.814393997192383, 47.151268005371094, 5.06871223449707, 8.434738159179688, 4.50958251953125, 14.559128761291504, 95.08751678466797, 7.188065528869629, 5.533731937408447, 9.915794372558594, 31.08172607421875, 5.444677829742432, 16.80910873413086, 265.7542724609375, 70.57071685791016, 187.4757537841797, 60.046409606933594, 27.861286163330078, 43.297203063964844, 754.6488647460938, 108.2962646484375, 84.95980834960938, 81.48779296875, 450.27117919921875, 412.845703125, 123.2854995727539, 79.51822662353516, 573.6831665039062, 292.2004699707031, 424.1375732421875, 234.74208068847656, 246.3928680419922, 116.23851013183594, 90.56785583496094, 313.25531005859375, 561.8568725585938, 213.12738037109375, 473.65399169921875, 420.675048828125, 303.6073913574219, 289.7061767578125, 657.3300170898438, 571.8602905273438, 533.548095703125, 414.13043212890625, 442.66229248046875, 271.23876953125, 178.37525939941406, 430.78106689453125, 298.3044738769531, 611.04931640625, 254.75975036621094, 509.8804931640625, 479.44378662109375, 308.63134765625, 434.702392578125, 302.820068359375, 392.3302307128906, 428.6229248046875, 424.8388671875, 453.6269836425781, 383.760986328125, 335.3272399902344, 348.5408935546875, 352.4817199707031, 384.59222412109375, 336.4886169433594, 338.8843994140625, 321.0252685546875, 6.913647174835205, 5.583402633666992, 8.493066787719727, 34.457794189453125, 4.575099468231201, 10.251618385314941, 6.234672546386719, 8.850502014160156, 3.8466081619262695, 3.8165550231933594, 10.89235782623291, 5.414668560028076, 7.523203372955322, 8.570306777954102, 3.72156023979187, 3.703066349029541, 3.161351203918457, 5.764560699462891, 3.1397202014923096, 4.139641284942627, 4.136347770690918, 4.643775463104248, 6.168365001678467, 5.135217189788818, 6.653196811676025, 92.01699829101562, 3.0591371059417725, 11.209216117858887, 3.0543859004974365, 4.064953804016113, 42.56232833862305, 12.068022727966309, 41.39817428588867, 59.6940803527832, 45.341060638427734, 15.00605297088623, 15.931800842285156, 19.729097366333008, 304.55487060546875, 231.22158813476562, 203.9136199951172, 64.4029312133789, 296.8027038574219, 292.677978515625, 333.4358215332031, 264.7412109375, 330.5676574707031, 50.69819259643555, 326.2620544433594, 482.6819152832031, 422.84259033203125, 360.9225158691406, 341.9850769042969, 162.6605987548828, 345.2870178222656, 703.337890625, 434.08905029296875, 548.1671142578125, 351.7231140136719, 494.9095153808594, 463.2158508300781, 234.29981994628906, 508.36614990234375, 218.18612670898438, 432.4728698730469, 176.30307006835938, 327.8702087402344, 226.28697204589844, 487.22216796875, 384.9351806640625, 338.8522644042969, 506.84619140625, 480.932373046875, 444.3594665527344, 461.378173828125, 449.06683349609375, 345.61553955078125, 404.88427734375, 346.36029052734375, 360.748291015625, 350.1978454589844, 332.66607666015625, 329.0847473144531], \"Total\": [1557.0, 956.0, 1444.0, 861.0, 1279.0, 654.0, 1892.0, 941.0, 896.0, 492.0, 1786.0, 1210.0, 942.0, 1182.0, 687.0, 685.0, 1029.0, 787.0, 1053.0, 680.0, 360.0, 1035.0, 783.0, 776.0, 1152.0, 567.0, 617.0, 577.0, 897.0, 1110.0, 12.914131164550781, 295.9424133300781, 7.9088897705078125, 10.880697250366211, 50.483863830566406, 35.65751647949219, 16.80862808227539, 22.764087677001953, 13.824270248413086, 257.1654052734375, 24.730623245239258, 60.313560485839844, 19.71691131591797, 654.39111328125, 19.7840576171875, 11.860162734985352, 18.82980728149414, 6.93187141418457, 23.75183868408203, 62.25262451171875, 32.61621856689453, 8.920534133911133, 33.62354278564453, 5.937911033630371, 25.684335708618164, 125.36810302734375, 941.1002197265625, 5.924887180328369, 9.87847900390625, 50.37143325805664, 147.237548828125, 67.23749542236328, 194.9565887451172, 1029.6826171875, 897.3638305664062, 526.3854370117188, 1152.096435546875, 551.935791015625, 434.22760009765625, 721.3479614257812, 271.80084228515625, 415.7677001953125, 911.9631958007812, 465.49029541015625, 834.8529052734375, 1451.997802734375, 657.965087890625, 896.543701171875, 141.0436248779297, 704.1078491210938, 715.5606689453125, 1398.3812255859375, 1035.3201904296875, 1200.6141357421875, 640.5607299804688, 1786.267333984375, 1582.068359375, 1109.719970703125, 611.9957275390625, 1110.073486328125, 1119.183349609375, 772.978515625, 881.3837890625, 1600.2386474609375, 952.3692626953125, 1066.174072265625, 1162.6597900390625, 1318.6806640625, 1398.824462890625, 1540.01025390625, 1557.4349365234375, 1441.9041748046875, 1556.315673828125, 1235.9305419921875, 1892.26171875, 1385.469970703125, 1385.5, 45.53515625, 11.834733963012695, 10.857461929321289, 92.83102416992188, 15.82168960571289, 32.64104461669922, 10.878827095031738, 37.4503059387207, 74.15567016601562, 26.684232711791992, 8.922188758850098, 6.92080020904541, 9.888221740722656, 44.434783935546875, 9.885902404785156, 39.44546890258789, 6.9030585289001465, 41.45425796508789, 82.12178802490234, 8.86788558959961, 14.799765586853027, 7.923251152038574, 25.626203536987305, 167.75889587402344, 12.818947792053223, 9.893736839294434, 17.75665283203125, 56.19142150878906, 9.883716583251953, 30.522768020629883, 492.3090515136719, 129.1410675048828, 360.45794677734375, 112.49568176269531, 51.3366584777832, 80.98931121826172, 1557.4349365234375, 209.27488708496094, 162.9750518798828, 156.51025390625, 942.1957397460938, 861.6365966796875, 243.88458251953125, 153.7605743408203, 1279.377197265625, 624.4424438476562, 956.4984130859375, 507.4361267089844, 537.8594970703125, 238.32220458984375, 181.35836791992188, 722.5001220703125, 1398.824462890625, 478.6170654296875, 1182.701904296875, 1033.919921875, 714.4027099609375, 686.32275390625, 1786.267333984375, 1556.315673828125, 1444.900634765625, 1083.062744140625, 1173.65185546875, 664.7473754882812, 400.15179443359375, 1182.2891845703125, 762.715087890625, 1892.26171875, 626.5101928710938, 1540.01025390625, 1441.9041748046875, 812.736328125, 1385.5, 809.2348022460938, 1200.6141357421875, 1398.3812255859375, 1385.469970703125, 1600.2386474609375, 1210.0157470703125, 959.0060424804688, 1066.174072265625, 1162.6597900390625, 1582.068359375, 1070.2548828125, 1119.183349609375, 1318.6806640625, 10.688904762268066, 8.749241828918457, 13.614678382873535, 58.429840087890625, 7.79246187210083, 17.536853790283203, 10.716989517211914, 15.597269058227539, 6.824177265167236, 6.8266401290893555, 19.502941131591797, 9.751890182495117, 13.65336799621582, 15.609804153442383, 6.8281331062316895, 6.830471515655518, 5.855783462524414, 10.734342575073242, 5.855587005615234, 7.807460784912109, 7.803673267364502, 8.784893035888672, 11.712127685546875, 9.763899803161621, 12.687671661376953, 175.7368621826172, 5.857763290405273, 21.480445861816406, 5.858572006225586, 7.812494277954102, 82.02101135253906, 23.439529418945312, 82.069091796875, 120.18502044677734, 90.88169860839844, 29.305988311767578, 31.26291275024414, 39.072906494140625, 687.3024291992188, 516.818115234375, 453.269775390625, 135.98446655273438, 680.714599609375, 685.0407104492188, 787.991943359375, 617.0341796875, 783.161376953125, 106.5933609008789, 776.32666015625, 1210.0157470703125, 1053.2606201171875, 897.543212890625, 847.177734375, 380.0789489746094, 862.9456787109375, 1892.26171875, 1113.72509765625, 1444.900634765625, 890.719482421875, 1318.6806640625, 1235.9305419921875, 577.2035522460938, 1385.5, 541.4443359375, 1182.2891845703125, 425.6244812011719, 870.9111328125, 567.7420043945312, 1385.469970703125, 1110.073486328125, 956.4984130859375, 1600.2386474609375, 1540.01025390625, 1441.9041748046875, 1582.068359375, 1556.315673828125, 1070.2548828125, 1451.997802734375, 1083.062744140625, 1279.377197265625, 1173.65185546875, 1035.3201904296875, 1162.6597900390625], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -9.661700248718262, -6.559700012207031, -10.217399597167969, -9.904899597167969, -8.370400428771973, -8.719900131225586, -9.472399711608887, -9.17199993133545, -9.675000190734863, -6.7718000411987305, -9.113800048828125, -8.229999542236328, -9.34939956665039, -5.847499847412109, -9.347299575805664, -9.859399795532227, -9.399800300598145, -10.403200149536133, -9.173299789428711, -8.215200424194336, -8.864100456237793, -10.160599708557129, -8.83430004119873, -10.569199562072754, -9.105400085449219, -7.520899772644043, -5.509900093078613, -10.581000328063965, -10.071000099182129, -8.447400093078613, -7.380799770355225, -8.161399841308594, -7.108500003814697, -5.4644999504089355, -5.618100166320801, -6.143899917602539, -5.376800060272217, -6.098299980163574, -6.3491997718811035, -5.857500076293945, -6.804599761962891, -6.398900032043457, -5.64709997177124, -6.299799919128418, -5.739099979400635, -5.223400115966797, -5.976900100708008, -5.691400051116943, -7.452400207519531, -5.935100078582764, -5.921299934387207, -5.30649995803833, -5.589799880981445, -5.462500095367432, -6.048500061035156, -5.111100196838379, -5.225299835205078, -5.583600044250488, -6.119699954986572, -5.605899810791016, -5.600200176239014, -5.925300121307373, -5.8171000480651855, -5.365499973297119, -5.768599987030029, -5.688000202178955, -5.650599956512451, -5.606599807739258, -5.57480001449585, -5.518199920654297, -5.5229997634887695, -5.576499938964844, -5.543700218200684, -5.657299995422363, -5.467299938201904, -5.6666998863220215, -5.734399795532227, -8.246299743652344, -9.62339973449707, -9.710399627685547, -7.571199893951416, -9.366900444030762, -8.65429973602295, -9.760299682617188, -8.561100006103516, -7.903299808502197, -8.92650032043457, -10.022100448608398, -10.279999732971191, -9.925000190734863, -8.42609977722168, -9.936800003051758, -8.553400039672852, -10.30049991607666, -8.508700370788574, -7.8256001472473145, -10.055899620056152, -9.546600341796875, -10.172800064086914, -9.000800132751465, -7.124199867248535, -9.706600189208984, -9.968099594116211, -9.38479995727539, -8.242400169372559, -9.984299659729004, -8.857099533081055, -6.096399784088135, -7.422399997711182, -6.445300102233887, -7.583899974822998, -8.351699829101562, -7.910900115966797, -5.052700042724609, -6.994100093841553, -7.236800193786621, -7.278500080108643, -5.5690999031066895, -5.655900001525879, -6.864500045776367, -7.302999973297119, -5.326900005340576, -6.001500129699707, -5.628900051116943, -6.2204999923706055, -6.171999931335449, -6.923299789428711, -7.172900199890137, -5.932000160217285, -5.347700119018555, -6.3171000480651855, -5.518499851226807, -5.6371002197265625, -5.963200092315674, -6.0100998878479, -5.190800189971924, -5.330100059509277, -5.399400234222412, -5.6528000831604, -5.58620023727417, -6.076000213623047, -6.495100021362305, -5.613399982452393, -5.980899810791016, -5.263800144195557, -6.138700008392334, -5.444799900054932, -5.50629997253418, -5.946800231933594, -5.604300022125244, -5.965799808502197, -5.706900119781494, -5.6184000968933105, -5.627299785614014, -5.561699867248535, -5.729000091552734, -5.863900184631348, -5.825200080871582, -5.814000129699707, -5.726799964904785, -5.860400199890137, -5.853300094604492, -5.90749979019165, -9.681599617004395, -9.895299911499023, -9.475899696350098, -8.075400352478027, -10.094499588012695, -9.287699699401855, -9.78499984741211, -9.434599876403809, -10.267900466918945, -10.275799751281738, -9.227100372314453, -9.925999641418457, -9.597100257873535, -9.46679973602295, -10.300999641418457, -10.305999755859375, -10.464099884033203, -9.86340045928955, -10.470999717712402, -10.194499969482422, -10.195300102233887, -10.07960033416748, -9.795700073242188, -9.979000091552734, -9.720000267028809, -7.093200206756592, -10.496999740600586, -9.198399543762207, -10.498499870300293, -10.212699890136719, -7.864200115203857, -9.124600410461426, -7.891900062561035, -7.525899887084961, -7.800899982452393, -8.906700134277344, -8.846799850463867, -8.633000373840332, -5.896299839019775, -6.1717000007629395, -6.297399997711182, -7.449999809265137, -5.922100067138672, -5.936100006103516, -5.805699825286865, -6.036399841308594, -5.814300060272217, -7.689199924468994, -5.827400207519531, -5.435800075531006, -5.5680999755859375, -5.726500034332275, -5.780399799346924, -6.523499965667725, -5.770699977874756, -5.059299945831299, -5.541900157928467, -5.308499813079834, -5.752299785614014, -5.410699844360352, -5.476900100708008, -6.1585001945495605, -5.383900165557861, -6.229800224304199, -5.545599937438965, -6.44290018081665, -5.822500228881836, -6.193299770355225, -5.426400184631348, -5.6620001792907715, -5.789599895477295, -5.386899948120117, -5.4394001960754395, -5.518499851226807, -5.480899810791016, -5.507999897003174, -5.769800186157227, -5.611499786376953, -5.767600059509277, -5.726900100708008, -5.7565999031066895, -5.808000087738037, -5.81879997253418], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.5895000100135803, 0.5597000122070312, 0.5241000056266785, 0.5175999999046326, 0.5174999833106995, 0.5156000256538391, 0.5152999758720398, 0.5123999714851379, 0.5080999732017517, 0.4880000054836273, 0.4876999855041504, 0.4799000024795532, 0.47859999537467957, 0.478300005197525, 0.4772999882698059, 0.47690001130104065, 0.4742000102996826, 0.4702000021934509, 0.4684999883174896, 0.46309998631477356, 0.46059998869895935, 0.46059998869895935, 0.46000000834465027, 0.45890000462532043, 0.45820000767707825, 0.45730000734329224, 0.45249998569488525, 0.44929999113082886, 0.448199987411499, 0.44269999861717224, 0.4366999864578247, 0.4399000108242035, 0.42820000648498535, 0.40799999237060547, 0.3919000029563904, 0.39959999918937683, 0.38339999318122864, 0.3977999985218048, 0.38670000433921814, 0.3709000051021576, 0.39980000257492065, 0.3804999887943268, 0.3467999994754791, 0.36660000681877136, 0.3431999981403351, 0.305400013923645, 0.3434000015258789, 0.31949999928474426, 0.40799999237060547, 0.3174999952316284, 0.3151000142097473, 0.2599000036716461, 0.27730000019073486, 0.2563999891281128, 0.2985999882221222, 0.21050000190734863, 0.21770000457763672, 0.21410000324249268, 0.27309998869895935, 0.19140000641345978, 0.1889999955892563, 0.23399999737739563, 0.21089999377727509, 0.06599999964237213, 0.18199999630451202, 0.14970000088214874, 0.10040000081062317, 0.01850000023841858, -0.008700000122189522, -0.04820000007748604, -0.06430000066757202, -0.040699999779462814, -0.08420000225305557, 0.032600000500679016, -0.20329999923706055, -0.09099999815225601, -0.15870000422000885, 0.744700014591217, 0.7150999903678894, 0.7142000198364258, 0.7074999809265137, 0.6812000274658203, 0.6696000099182129, 0.6624000072479248, 0.6252999901771545, 0.6000000238418579, 0.5989000201225281, 0.5989000201225281, 0.5950000286102295, 0.5931000113487244, 0.5892999768257141, 0.58160001039505, 0.5812000036239624, 0.5770000219345093, 0.576200008392334, 0.5756999850273132, 0.5712000131607056, 0.5683000087738037, 0.5669000148773193, 0.5651000142097473, 0.5627999901771545, 0.5519999861717224, 0.5494999885559082, 0.5479000210762024, 0.5383999943733215, 0.5343000292778015, 0.5339999794960022, 0.5139999985694885, 0.526199996471405, 0.47679999470710754, 0.5026999711990356, 0.5194000005722046, 0.5042999982833862, 0.4059999883174896, 0.4717000126838684, 0.47909998893737793, 0.4778999984264374, 0.3921999931335449, 0.39480000734329224, 0.44830000400543213, 0.47110000252723694, 0.32850000262260437, 0.3711000084877014, 0.3172999918460846, 0.3596000075340271, 0.3499000072479248, 0.4124999940395355, 0.43619999289512634, 0.2948000133037567, 0.2184000015258789, 0.3215000033378601, 0.21539999544620514, 0.2312999963760376, 0.27480000257492065, 0.2680000066757202, 0.13079999387264252, 0.12929999828338623, 0.13429999351501465, 0.16920000314712524, 0.15549999475479126, 0.23409999907016754, 0.32260000705718994, 0.120899997651577, 0.19179999828338623, 0.00019999999494757503, 0.23070000112056732, 0.025200000032782555, 0.029400000348687172, 0.1623000055551529, -0.028599999845027924, 0.147599995136261, 0.012000000104308128, -0.052000001072883606, -0.051600001752376556, -0.13009999692440033, -0.017799999564886093, 0.07970000058412552, 0.012400000356137753, -0.06289999932050705, -0.28380000591278076, -0.026599999517202377, -0.06419999897480011, -0.2822999954223633, 0.7587000131607056, 0.745199978351593, 0.7225000262260437, 0.6662999987602234, 0.6618000268936157, 0.6575000286102295, 0.6527000069618225, 0.6277999877929688, 0.6211000084877014, 0.6129000186920166, 0.6118999719619751, 0.6060000061988831, 0.5983999967575073, 0.5947999954223633, 0.5874999761581421, 0.582099974155426, 0.5778999924659729, 0.572700023651123, 0.5710999965667725, 0.5598999857902527, 0.5595999956130981, 0.5569000244140625, 0.5532000064849854, 0.551800012588501, 0.548799991607666, 0.5473999977111816, 0.544700026512146, 0.5440000295639038, 0.5429999828338623, 0.541100025177002, 0.5383999943733215, 0.5304999947547913, 0.5099999904632568, 0.49459999799728394, 0.49900001287460327, 0.5249999761581421, 0.5202999711036682, 0.5109999775886536, 0.3804999887943268, 0.39010000228881836, 0.39559999108314514, 0.44699999690055847, 0.364300012588501, 0.3440000116825104, 0.3343000113964081, 0.3481999933719635, 0.33180001378059387, 0.451200008392334, 0.32749998569488525, 0.275299996137619, 0.2816999852657318, 0.2833999991416931, 0.287200003862381, 0.3456999957561493, 0.2784000039100647, 0.20469999313354492, 0.25220000743865967, 0.22519999742507935, 0.2651999890804291, 0.21439999341964722, 0.21299999952316284, 0.29280000925064087, 0.19179999828338623, 0.2854999899864197, 0.18870000541210175, 0.31299999356269836, 0.2175000011920929, 0.2745000123977661, 0.1492999941110611, 0.13529999554157257, 0.156700000166893, 0.04470000043511391, 0.03060000017285347, 0.01730000041425228, -0.03790000081062317, -0.048500001430511475, 0.06400000303983688, -0.08269999921321869, 0.05429999902844429, -0.07159999758005142, -0.014999999664723873, 0.05900000035762787, -0.06780000030994415]}, \"token.table\": {\"Topic\": [1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3], \"Freq\": [0.3853161931037903, 0.1997065544128418, 0.4135100543498993, 0.269662469625473, 0.4486558139324188, 0.28216853737831116, 0.25929346680641174, 0.5309342741966248, 0.2099042385816574, 0.5270389318466187, 0.2515413165092468, 0.22039811313152313, 0.34376057982444763, 0.36753469705581665, 0.28850188851356506, 0.2755114734172821, 0.29495933651924133, 0.42947378754615784, 0.2589835226535797, 0.2968125641345978, 0.4437638819217682, 0.615003764629364, 0.175715371966362, 0.175715371966362, 0.2842938303947449, 0.31735125184059143, 0.39916837215423584, 0.3220752477645874, 0.40718820691108704, 0.2708140015602112, 0.29082486033439636, 0.23453618586063385, 0.4784538149833679, 0.23402856290340424, 0.5460666418075562, 0.23402856290340424, 0.6065354347229004, 0.202178493142128, 0.202178493142128, 0.3356800079345703, 0.486735999584198, 0.1762320101261139, 0.49183350801467896, 0.26307374238967896, 0.2450997531414032, 0.2023082822561264, 0.6069248914718628, 0.2023082822561264, 0.1400393843650818, 0.6571078896522522, 0.2046729475259781, 0.5825322866439819, 0.1839575618505478, 0.21461714804172516, 0.2276635617017746, 0.2276635617017746, 0.5691589117050171, 0.11276645213365555, 0.5638322830200195, 0.2255329042673111, 0.16381214559078217, 0.5569612979888916, 0.2948618531227112, 0.1866195648908615, 0.1866195648908615, 0.5598587393760681, 0.5968806743621826, 0.19896022975444794, 0.19896022975444794, 0.22859123349189758, 0.11429561674594879, 0.6857737302780151, 0.25665828585624695, 0.12832914292812347, 0.6416457295417786, 0.5420407652854919, 0.2758724093437195, 0.18160444498062134, 0.31136924028396606, 0.463112473487854, 0.2246588170528412, 0.5592330098152161, 0.22810819745063782, 0.21339154243469238, 0.6169807314872742, 0.22435662150382996, 0.16826747357845306, 0.28412288427352905, 0.4225417375564575, 0.292865127325058, 0.2761327922344208, 0.4070165157318115, 0.3176324963569641, 0.22248905897140503, 0.18825997412204742, 0.5818944573402405, 0.2274993658065796, 0.5403109788894653, 0.23156185448169708, 0.30991438031196594, 0.47760775685310364, 0.2122701108455658, 0.30454057455062866, 0.29155629873275757, 0.4036933183670044, 0.48556143045425415, 0.3067832887172699, 0.20809775590896606, 0.08449704200029373, 0.6759763360023499, 0.2534911334514618, 0.6065489649772644, 0.20218299329280853, 0.20218299329280853, 0.4202495217323303, 0.2032354325056076, 0.37661707401275635, 0.6036145687103271, 0.14364498853683472, 0.25367093086242676, 0.24261356890201569, 0.501768946647644, 0.25915539264678955, 0.14653781056404114, 0.2930756211280823, 0.5861512422561646, 0.292805552482605, 0.1464027762413025, 0.58561110496521, 0.3160676658153534, 0.45736852288246155, 0.2268250435590744, 0.5772984027862549, 0.19696062803268433, 0.2241276055574417, 0.6969109773635864, 0.2323036640882492, 0.07743455469608307, 0.5562241077423096, 0.2119811773300171, 0.23191103339195251, 0.4839189946651459, 0.3264995813369751, 0.18990281224250793, 0.17069005966186523, 0.17069005966186523, 0.5120701789855957, 0.3512185215950012, 0.4847714602947235, 0.16437283158302307, 0.3592471778392792, 0.3321996033191681, 0.30792614817619324, 0.386753112077713, 0.23868654668331146, 0.3746165335178375, 0.29991209506988525, 0.25347408652305603, 0.446965754032135, 0.23276984691619873, 0.23276984691619873, 0.5120936632156372, 0.3564911186695099, 0.3311666250228882, 0.3123355805873871, 0.3359449803829193, 0.4255303144454956, 0.23936079442501068, 0.5128845572471619, 0.2822961211204529, 0.20543330907821655, 0.5296266078948975, 0.2478170245885849, 0.22259670495986938, 0.3054545819759369, 0.32289403676986694, 0.37151309847831726, 0.5075765252113342, 0.21349895000457764, 0.2789260447025299, 0.5392163991928101, 0.3072029650211334, 0.15467561781406403, 0.2878810465335846, 0.2239074856042862, 0.511788547039032, 0.26789480447769165, 0.5723206996917725, 0.1583014726638794, 0.18961311876773834, 0.632043719291687, 0.18961311876773834, 0.3300994634628296, 0.1650497317314148, 0.4951491951942444, 0.4652137756347656, 0.24335232377052307, 0.29139068722724915, 0.3086504638195038, 0.4332179129123688, 0.25743940472602844, 0.5902111530303955, 0.16863174736499786, 0.2529476284980774, 0.335683673620224, 0.2694450914859772, 0.3951861560344696, 0.21710677444934845, 0.578951358795166, 0.21710677444934845, 0.27298176288604736, 0.20473630726337433, 0.5118407607078552, 0.2952779233455658, 0.2688351273536682, 0.4363062083721161, 0.25122836232185364, 0.3695755898952484, 0.37926483154296875, 0.5504025816917419, 0.26253512501716614, 0.18653811514377594, 0.29296988248825073, 0.14648494124412537, 0.5859397649765015, 0.20863275229930878, 0.5662888884544373, 0.22651556134223938, 0.3246277868747711, 0.37745434045791626, 0.29821449518203735, 0.33624035120010376, 0.5604006052017212, 0.11208011955022812, 0.5063387751579285, 0.16877958178520203, 0.16877958178520203, 0.5483831763267517, 0.28621751070022583, 0.16595806181430817, 0.4734930992126465, 0.2587394118309021, 0.2690889835357666, 0.22762662172317505, 0.520289421081543, 0.2536410987377167, 0.3753886818885803, 0.34932002425193787, 0.2752850353717804, 0.46317991614341736, 0.2604260742664337, 0.27664637565612793, 0.37102583050727844, 0.401765912771225, 0.22733373939990997, 0.3676890432834625, 0.16178318858146667, 0.47064200043678284, 0.45211538672447205, 0.30289942026138306, 0.24482136964797974, 0.22809109091758728, 0.17106831073760986, 0.5702276825904846, 0.18710990250110626, 0.18710990250110626, 0.6548846960067749, 0.26877665519714355, 0.39070945978164673, 0.3408874571323395, 0.34154269099235535, 0.17077134549617767, 0.5123140215873718, 0.5042456984519958, 0.29349285364151, 0.20294718444347382, 0.3490663468837738, 0.2474862039089203, 0.40262681245803833, 0.5894280672073364, 0.2105100154876709, 0.16840802133083344, 0.5605045557022095, 0.22420182824134827, 0.11210091412067413, 0.5585260987281799, 0.25836580991744995, 0.18237586319446564, 0.43426305055618286, 0.32733866572380066, 0.2382350116968155, 0.655532956123352, 0.16557274758815765, 0.17908889055252075, 0.5840135216712952, 0.19467118382453918, 0.23360541462898254, 0.20270591974258423, 0.540549099445343, 0.20270591974258423, 0.5841801762580872, 0.26553642749786377, 0.1593218594789505, 0.6086146235466003, 0.10143576562404633, 0.30430731177330017, 0.6322000026702881, 0.12644000351428986, 0.2528800070285797, 0.17568843066692352, 0.6807926297187805, 0.13176631927490234, 0.4935671091079712, 0.18448399007320404, 0.32163962721824646, 0.2929058372974396, 0.2929058372974396, 0.5858116745948792, 0.3298943042755127, 0.4676171541213989, 0.20178000628948212, 0.3190183937549591, 0.3139660656452179, 0.366654634475708, 0.4494055211544037, 0.25305309891700745, 0.29820364713668823, 0.3027551472187042, 0.37442779541015625, 0.3225269019603729, 0.29822832345962524, 0.3822493255138397, 0.31946441531181335, 0.5757231712341309, 0.1786727011203766, 0.23823027312755585, 0.31794214248657227, 0.26048269867897034, 0.4226459562778473, 0.09210255742073059, 0.6447178721427917, 0.18420511484146118, 0.321760356426239, 0.44503217935562134, 0.23191818594932556, 0.34986722469329834, 0.4448311924934387, 0.20492222905158997, 0.4617738723754883, 0.29612526297569275, 0.24166543781757355, 0.38391879200935364, 0.18830998241901398, 0.4277118146419525, 0.25624921917915344, 0.19218690693378448, 0.5765607357025146, 0.3814418613910675, 0.24342511594295502, 0.3753751814365387, 0.21972601115703583, 0.21972601115703583, 0.5859360098838806, 0.2564551532268524, 0.19234135746955872, 0.5770241022109985, 0.26474300026893616, 0.2868049144744873, 0.4500631093978882, 0.25242164731025696, 0.6310541033744812, 0.12621082365512848, 0.6073809266090393, 0.20246031880378723, 0.20246031880378723, 0.6338658928871155, 0.1980830878019333, 0.17827478051185608, 0.19974590837955475, 0.5187845230102539, 0.2801991105079651, 0.1707770675420761, 0.1707770675420761, 0.5123311877250671, 0.2698155343532562, 0.3645470142364502, 0.3653928339481354, 0.4618569612503052, 0.367806077003479, 0.17018729448318481, 0.5632803440093994, 0.2204562872648239, 0.21754276752471924, 0.21445392072200775, 0.6433617472648621, 0.15318137407302856, 0.30725428462028503, 0.2048361897468567, 0.5120904445648193, 0.5273836255073547, 0.25685253739356995, 0.2158169150352478, 0.5943524241447449, 0.17669937014579773, 0.2248901128768921, 0.23559816181659698, 0.4793204069137573, 0.28550317883491516, 0.20133022964000702, 0.549786388874054, 0.24779105186462402, 0.6510289311408997, 0.14467309415340424, 0.21700964868068695, 0.20508845150470734, 0.20508845150470734, 0.5127211213111877, 0.28289714455604553, 0.22465361654758453, 0.4992302656173706, 0.3035295307636261, 0.5058825612068176, 0.20235303044319153, 0.33837586641311646, 0.26073482632637024, 0.399793416261673, 0.6544257998466492, 0.17847976088523865, 0.23797301948070526, 0.6736375689506531, 0.16840939223766327, 0.16840939223766327, 0.5800334811210632, 0.2230898141860962, 0.20821715891361237, 0.3625304698944092, 0.31394389271736145, 0.3232874870300293, 0.19575941562652588, 0.551685631275177, 0.24914835393428802, 0.30764591693878174, 0.15382295846939087, 0.5640174746513367, 0.1448633223772049, 0.5794532895088196, 0.2897266447544098, 0.20254401862621307, 0.5851271748542786, 0.20254401862621307, 0.29243651032447815, 0.20714253187179565, 0.4995790719985962, 0.177460178732872, 0.58308345079422, 0.25351452827453613, 0.1707136183977127, 0.3414272367954254, 0.5121408700942993, 0.23033863306045532, 0.2559318244457245, 0.511863648891449, 0.3414003849029541, 0.3067551255226135, 0.3515052795410156, 0.5601103901863098, 0.17016011476516724, 0.26942017674446106, 0.1281447857618332, 0.3844343423843384, 0.5125791430473328, 0.3114139139652252, 0.2867286503314972, 0.40161001682281494, 0.23778405785560608, 0.3646022379398346, 0.3980681300163269, 0.33042263984680176, 0.2792430520057678, 0.38968324661254883, 0.2337510883808136, 0.5454192161560059, 0.21427182853221893, 0.19511279463768005, 0.5853383541107178, 0.23413534462451935, 0.1852913796901703, 0.5175379514694214, 0.2939104437828064, 0.35279548168182373, 0.22462157905101776, 0.4225931465625763, 0.12808261811733246, 0.2561652362346649, 0.5123304724693298, 0.25606465339660645, 0.22192271053791046, 0.5235099792480469, 0.2788204252719879, 0.5043368935585022, 0.2173159122467041, 0.5141257643699646, 0.2556426525115967, 0.23007838428020477, 0.17076316475868225, 0.3415263295173645, 0.5122895240783691, 0.24601373076438904, 0.3482307195663452, 0.40540289878845215, 0.24000921845436096, 0.5333538055419922, 0.23111997544765472, 0.303222119808197, 0.606444239616394, 0.20214809477329254, 0.5948213338851929, 0.20818746089935303, 0.20818746089935303, 0.34392738342285156, 0.2357255071401596, 0.41992631554603577, 0.5886726975440979, 0.2412070482969284, 0.17001377046108246, 0.15763333439826965, 0.3152666687965393, 0.551716685295105, 0.2252676784992218, 0.5631691813468933, 0.2252676784992218, 0.3999403417110443, 0.2837076783180237, 0.3168277442455292, 0.28898391127586365, 0.5779678225517273, 0.14449195563793182, 0.20282313227653503, 0.4432835280895233, 0.35441774129867554, 0.549433171749115, 0.22914747893810272, 0.22133563458919525, 0.22485189139842987, 0.5996050238609314, 0.18737657368183136, 0.2022608369588852, 0.6067824959754944, 0.2022608369588852, 0.41370657086372375, 0.30275407433509827, 0.2829718589782715, 0.1335102617740631, 0.6141471862792969, 0.2670205235481262, 0.24731703102588654, 0.32624801993370056, 0.42885828018188477, 0.2580338418483734, 0.5160676836967468, 0.22458499670028687, 0.2559778392314911, 0.2559778392314911, 0.5119556784629822, 0.18631789088249207, 0.2794768214225769, 0.5589536428451538, 0.5744868516921997, 0.24620865285396576, 0.179527148604393, 0.14690028131008148, 0.22035041451454163, 0.5876011252403259, 0.45312315225601196, 0.1999867558479309, 0.34682387113571167, 0.18384334444999695, 0.6434516906738281, 0.18384334444999695, 0.3320174515247345, 0.26628243923187256, 0.4022090435028076, 0.5902617573738098, 0.15953020751476288, 0.2472718209028244, 0.5153123140335083, 0.15503984689712524, 0.3301568031311035, 0.5538444519042969, 0.20170190930366516, 0.24516254663467407, 0.30760282278060913, 0.38019710779190063, 0.3125244677066803, 0.35342803597450256, 0.40077725052833557, 0.246046781539917, 0.25600019097328186, 0.25600019097328186, 0.5120003819465637, 0.6105020046234131, 0.29164108633995056, 0.09721370041370392, 0.6433411240577698, 0.183811753988266, 0.183811753988266, 0.27611589431762695, 0.5215522050857544, 0.20248498022556305, 0.34449177980422974, 0.4076736569404602, 0.24821458756923676, 0.29260796308517456, 0.1950719654560089, 0.5242559313774109, 0.5770447254180908, 0.2885223627090454, 0.1442611813545227, 0.24273261427879333, 0.5933464169502258, 0.17530688643455505], \"Term\": [\"add\", \"add\", \"add\", \"amazing\", \"amazing\", \"amazing\", \"apartment\", \"apartment\", \"apartment\", \"area\", \"area\", \"area\", \"ask\", \"ask\", \"ask\", \"away\", \"away\", \"away\", \"awesome\", \"awesome\", \"awesome\", \"backyard\", \"backyard\", \"backyard\", \"bad\", \"bad\", \"bad\", \"bar\", \"bar\", \"bar\", \"barely\", \"barely\", \"barely\", \"bat\", \"bat\", \"bat\", \"batch\", \"batch\", \"batch\", \"bbq\", \"bbq\", \"bbq\", \"beer\", \"beer\", \"beer\", \"bella\", \"bella\", \"bella\", \"bike\", \"bike\", \"bike\", \"brake\", \"brake\", \"brake\", \"bravo\", \"bravo\", \"bravo\", \"brooklyn\", \"brooklyn\", \"brooklyn\", \"brow\", \"brow\", \"brow\", \"brussels\", \"brussels\", \"brussels\", \"buffalo\", \"buffalo\", \"buffalo\", \"bulwark\", \"bulwark\", \"bulwark\", \"bundle\", \"bundle\", \"bundle\", \"burger\", \"burger\", \"burger\", \"buy\", \"buy\", \"buy\", \"cake\", \"cake\", \"cake\", \"cappuccino\", \"cappuccino\", \"cappuccino\", \"car\", \"car\", \"car\", \"care\", \"care\", \"care\", \"cat\", \"cat\", \"cat\", \"charge\", \"charge\", \"charge\", \"check\", \"check\", \"check\", \"cheese\", \"cheese\", \"cheese\", \"chicken\", \"chicken\", \"chicken\", \"christina\", \"christina\", \"christina\", \"cider\", \"cider\", \"cider\", \"clean\", \"clean\", \"clean\", \"coffee\", \"coffee\", \"coffee\", \"color\", \"color\", \"color\", \"compassionate\", \"compassionate\", \"compassionate\", \"comprehensive\", \"comprehensive\", \"comprehensive\", \"cook\", \"cook\", \"cook\", \"cookie\", \"cookie\", \"cookie\", \"cosmo\", \"cosmo\", \"cosmo\", \"cream\", \"cream\", \"cream\", \"customer\", \"customer\", \"customer\", \"dank\", \"dank\", \"dank\", \"day\", \"day\", \"day\", \"definitely\", \"definitely\", \"definitely\", \"delicious\", \"delicious\", \"delicious\", \"dessert\", \"dessert\", \"dessert\", \"diagnose\", \"diagnose\", \"diagnose\", \"didn\", \"didn\", \"didn\", \"different\", \"different\", \"different\", \"dinner\", \"dinner\", \"dinner\", \"dish\", \"dish\", \"dish\", \"don\", \"don\", \"don\", \"drink\", \"drink\", \"drink\", \"drive\", \"drive\", \"drive\", \"dryer\", \"dryer\", \"dryer\", \"dumpling\", \"dumpling\", \"dumpling\", \"dutch\", \"dutch\", \"dutch\", \"east\", \"east\", \"east\", \"eat\", \"eat\", \"eat\", \"end\", \"end\", \"end\", \"enhance\", \"enhance\", \"enhance\", \"enjoy\", \"enjoy\", \"enjoy\", \"equipment\", \"equipment\", \"equipment\", \"escape\", \"escape\", \"escape\", \"excellent\", \"excellent\", \"excellent\", \"experience\", \"experience\", \"experience\", \"far\", \"far\", \"far\", \"faucet\", \"faucet\", \"faucet\", \"fee\", \"fee\", \"fee\", \"feel\", \"feel\", \"feel\", \"festival\", \"festival\", \"festival\", \"fiend\", \"fiend\", \"fiend\", \"finally\", \"finally\", \"finally\", \"flavor\", \"flavor\", \"flavor\", \"forward\", \"forward\", \"forward\", \"fresh\", \"fresh\", \"fresh\", \"friend\", \"friend\", \"friend\", \"friendly\", \"friendly\", \"friendly\", \"fruit\", \"fruit\", \"fruit\", \"fry\", \"fry\", \"fry\", \"german\", \"german\", \"german\", \"halo\", \"halo\", \"halo\", \"happy\", \"happy\", \"happy\", \"heaping\", \"heaping\", \"heaping\", \"help\", \"help\", \"help\", \"highly\", \"highly\", \"highly\", \"hollywood\", \"hollywood\", \"hollywood\", \"hooter\", \"hooter\", \"hooter\", \"hotel\", \"hotel\", \"hotel\", \"hour\", \"hour\", \"hour\", \"isn\", \"isn\", \"isn\", \"jean\", \"jean\", \"jean\", \"jordan\", \"jordan\", \"jordan\", \"karaoke\", \"karaoke\", \"karaoke\", \"knife\", \"knife\", \"knife\", \"lakewood\", \"lakewood\", \"lakewood\", \"lash\", \"lash\", \"lash\", \"leave\", \"leave\", \"leave\", \"lens\", \"lens\", \"lens\", \"line\", \"line\", \"line\", \"little\", \"little\", \"little\", \"location\", \"location\", \"location\", \"long\", \"long\", \"long\", \"lot\", \"lot\", \"lot\", \"lover\", \"lover\", \"lover\", \"lunch\", \"lunch\", \"lunch\", \"mailbox\", \"mailbox\", \"mailbox\", \"manager\", \"manager\", \"manager\", \"maybe\", \"maybe\", \"maybe\", \"meal\", \"meal\", \"meal\", \"meat\", \"meat\", \"meat\", \"meatloaf\", \"meatloaf\", \"meatloaf\", \"menu\", \"menu\", \"menu\", \"mmm\", \"mmm\", \"mmm\", \"mochi\", \"mochi\", \"mochi\", \"month\", \"month\", \"month\", \"moscow\", \"moscow\", \"moscow\", \"mrs\", \"mrs\", \"mrs\", \"naan\", \"naan\", \"naan\", \"nail\", \"nail\", \"nail\", \"neglect\", \"neglect\", \"neglect\", \"new\", \"new\", \"new\", \"nice\", \"nice\", \"nice\", \"night\", \"night\", \"night\", \"nope\", \"nope\", \"nope\", \"oct\", \"oct\", \"oct\", \"offer\", \"offer\", \"offer\", \"omg\", \"omg\", \"omg\", \"pay\", \"pay\", \"pay\", \"pedicure\", \"pedicure\", \"pedicure\", \"peruvian\", \"peruvian\", \"peruvian\", \"peter\", \"peter\", \"peter\", \"pho\", \"pho\", \"pho\", \"pierogi\", \"pierogi\", \"pierogi\", \"pizza\", \"pizza\", \"pizza\", \"poker\", \"poker\", \"poker\", \"pos\", \"pos\", \"pos\", \"poutine\", \"poutine\", \"poutine\", \"pretty\", \"pretty\", \"pretty\", \"print\", \"print\", \"print\", \"prix\", \"prix\", \"prix\", \"promoter\", \"promoter\", \"promoter\", \"protein\", \"protein\", \"protein\", \"pudding\", \"pudding\", \"pudding\", \"puppy\", \"puppy\", \"puppy\", \"realistic\", \"realistic\", \"realistic\", \"receptionist\", \"receptionist\", \"receptionist\", \"recommend\", \"recommend\", \"recommend\", \"refill\", \"refill\", \"refill\", \"reflexology\", \"reflexology\", \"reflexology\", \"right\", \"right\", \"right\", \"roll\", \"roll\", \"roll\", \"room\", \"room\", \"room\", \"root\", \"root\", \"root\", \"roti\", \"roti\", \"roti\", \"rush\", \"rush\", \"rush\", \"salad\", \"salad\", \"salad\", \"saver\", \"saver\", \"saver\", \"schedule\", \"schedule\", \"schedule\", \"sell\", \"sell\", \"sell\", \"serve\", \"serve\", \"serve\", \"shitty\", \"shitty\", \"shitty\", \"shop\", \"shop\", \"shop\", \"shot\", \"shot\", \"shot\", \"singer\", \"singer\", \"singer\", \"sip\", \"sip\", \"sip\", \"sit\", \"sit\", \"sit\", \"small\", \"small\", \"small\", \"smith\", \"smith\", \"smith\", \"spin\", \"spin\", \"spin\", \"staff\", \"staff\", \"staff\", \"supportive\", \"supportive\", \"supportive\", \"sure\", \"sure\", \"sure\", \"table\", \"table\", \"table\", \"talented\", \"talented\", \"talented\", \"tapioca\", \"tapioca\", \"tapioca\", \"taste\", \"taste\", \"taste\", \"tattoo\", \"tattoo\", \"tattoo\", \"tea\", \"tea\", \"tea\", \"terrible\", \"terrible\", \"terrible\", \"terribly\", \"terribly\", \"terribly\", \"threaten\", \"threaten\", \"threaten\", \"truly\", \"truly\", \"truly\", \"urgent\", \"urgent\", \"urgent\", \"use\", \"use\", \"use\", \"vape\", \"vape\", \"vape\", \"vegas\", \"vegas\", \"vegas\", \"vegetarian\", \"vegetarian\", \"vegetarian\", \"visit\", \"visit\", \"visit\", \"walk\", \"walk\", \"walk\", \"wasn\", \"wasn\", \"wasn\", \"way\", \"way\", \"way\", \"whisky\", \"whisky\", \"whisky\", \"wing\", \"wing\", \"wing\", \"wolf\", \"wolf\", \"wolf\", \"woman\", \"woman\", \"woman\", \"worth\", \"worth\", \"worth\", \"yesterday\", \"yesterday\", \"yesterday\", \"yummm\", \"yummm\", \"yummm\", \"zero\", \"zero\", \"zero\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [1, 2, 3]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el8056048449380089445094953\", ldavis_el8056048449380089445094953_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el8056048449380089445094953\", ldavis_el8056048449380089445094953_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el8056048449380089445094953\", ldavis_el8056048449380089445094953_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
       "topic                                                \n",
       "0     -0.010550 -0.001775       1        1  37.424339\n",
       "1      0.006955 -0.007472       2        1  32.286327\n",
       "2      0.003595  0.009247       3        1  30.289331, topic_info=           Term         Freq        Total Category  logprob  loglift\n",
       "351         day  1557.000000  1557.000000  Default  30.0000  30.0000\n",
       "86         sure   956.000000   956.000000  Default  29.0000  29.0000\n",
       "214  experience  1444.000000  1444.000000  Default  28.0000  28.0000\n",
       "101         pay   861.000000   861.000000  Default  27.0000  27.0000\n",
       "150     amazing  1279.000000  1279.000000  Default  26.0000  26.0000\n",
       "..          ...          ...          ...      ...      ...      ...\n",
       "700         lot   346.360291  1083.062744   Topic3  -5.7676   0.0543\n",
       "150     amazing   360.748291  1279.377197   Topic3  -5.7269  -0.0716\n",
       "217        feel   350.197845  1173.651855   Topic3  -5.7566  -0.0150\n",
       "12        leave   332.666077  1035.320190   Topic3  -5.8080   0.0590\n",
       "568       taste   329.084747  1162.659790   Topic3  -5.8188  -0.0678\n",
       "\n",
       "[276 rows x 6 columns], token_table=      Topic      Freq     Term\n",
       "term                          \n",
       "203       1  0.385316      add\n",
       "203       2  0.199707      add\n",
       "203       3  0.413510      add\n",
       "150       1  0.269662  amazing\n",
       "150       2  0.448656  amazing\n",
       "...     ...       ...      ...\n",
       "1583      2  0.288522    yummm\n",
       "1583      3  0.144261    yummm\n",
       "2000      1  0.242733     zero\n",
       "2000      2  0.593346     zero\n",
       "2000      3  0.175307     zero\n",
       "\n",
       "[621 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[1, 2, 3])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\", category = FutureWarning)\n",
    "\n",
    "pyLDAvis.enable_notebook()\n",
    "\n",
    "pyLDAvis.gensim.prepare(lda, corpus, id2word)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stretch Goals\n",
    "\n",
    "Complete one of more of these to push your score towards a three: \n",
    "* Incorporate named entity recognition into your analysis\n",
    "* Compare vectorization methods in the classification section\n",
    "* Analyze more (or all) of the yelp dataset - this one is v. hard. \n",
    "* Use a generator object on the reviews file - this would help you with the analyzing the whole dataset.\n",
    "* Incorporate any of the other yelp dataset entities in your analysis (business, users, etc.)"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "u4-s1-nlp"
  },
  "kernelspec": {
   "display_name": "U4-S1-NLP (Python3)",
   "language": "python",
   "name": "u4-s1-nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "nteract": {
   "version": "0.14.5"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
